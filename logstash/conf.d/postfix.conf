input {
  kafka {
    codec => "json"
    bootstrap_servers => "172.16.0.124:9092,172.16.0.125:9092,172.16.0.126:9092"
    topics => ["foxpostfixlog"]
    tags => "foxpostfixlog"
    }
}

filter{
if "foxpostfixlog" in [tags] {
grok {
match => {
  "message" => ["%{SYSLOGTIMESTAMP:log_time} %{HOSTNAME:host-postfix} %{DATA:process}\[%{INT:pid}\]: %{WORD:msgid}: to=<(?<to>[^>]+)>, %{GREEDYDATA:msg}",
                "%{SYSLOGTIMESTAMP:log_time} %{HOSTNAME:host-postfix} %{DATA:process}\[%{INT:pid}\]: %{WORD:msgid}: from=<(?<from>[^>]+)>, %{GREEDYDATA:msg}",
                "%{SYSLOGTIMESTAMP:log_time} %{HOSTNAME:host-postfix} %{DATA:process}\[%{INT:pid}\]: %{WORD:message-id}: message-id=<%{DATA:id}@%{DATA:service}>",
                "%{SYSLOGTIMESTAMP:log_time} %{GREEDYDATA:msg}"
]
}
}

mutate {
remove_field => "@timestamp"
}


date {
#match => ["time_stamp", "MMM  d HH:mm:ss", "MMM dd HH:mm:ss"]
match => ["log_time", "MMM  d HH:mm:ss", "MMM dd HH:mm:ss"]
target => "log_time"
}

}
}
output {
#stdout { codec => rubydebug }
    if "foxpostfixlog" in [tags] {
      elasticsearch {
      hosts => ["https://172.16.0.127:9200"]
      user => "elastic"
      password => "conan@123456"
      cacert => '/etc/logstash/conf.d/http_ca.crt'
      ilm_policy => "30-days-default"
      ilm_rollover_alias => "postfix-alias"
      ilm_pattern => "log-postfix-%{+yyyy.MM.dd}-000001"
    }
    }
}


