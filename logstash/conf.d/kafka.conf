input {
    kafka  {
        codec => "json"
        #"Nginx" should be consistent with the topic configured in filebeat.
        topics_pattern => "test-1"
        #Configure Kafka server cluster address here
        bootstrap_servers => "10.26.7.96:9092"
        auto_offset_reset => "latest"
   }
}

filter {
#    Convert the request time in the Nginx log to Beijing time, and assign it to @ timestamp to ensure that the log time is consistent with @ timestamp
    date {
        match => ["requesttime", "dd/MMM/yyyy:HH:mm:ss Z +08:00"]
        target => "@timestamp"
}
#Introduce the third time parameter timestamp, add 8 hours to the above @ timestamp time, and assign it to timestamp to prevent ES from subtracting 8 hours from the time, resulting in 8 hours difference between the two times
    ruby {
        code => "event.set('timestamp', event.get('@timestamp').time.utc+8*60*60)"
    }
    mutate {
        convert => ["timestamp", "string"]
        gsub => ["timestamp", "T([\S\s]*?)Z", ""]
        gsub => ["timestamp", "-", "."]
    }
    mutate {
        remove_field => ["_index"]
        remove_field => ["_id"]
        remove_field => ["_type"]
        remove_field => ["_version"]
        remove_field => ["_score"]
        remove_field => ["host"]
        remove_field => ["log"]
        remove_field => ["referer"]
        remove_field => ["input"]
        remove_field => ["path"]
        remove_field => ["agent"]
    }
}

output {
    elasticsearch {
        hosts => ["https://ip:9200"]
		user => "elastic"
		password => "default"
		ssl_certificate_verification => false
		ilm_pattern => "{now/d}-000001"
        ilm_rollover_alias => "kafka-alias"
        ilm_policy => "kafka-policy"
		index => "%{[@metadata][kafka]}-%{now/d}"
		document_type => "%{[@metadata][type]}"
        }
}
