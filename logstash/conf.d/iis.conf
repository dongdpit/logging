input {
    kafka  {
        codec => "json"
        #"Nginx" should be consistent with the topic configured in filebeat.
        topics_pattern => "iis-log"
        #Configure Kafka server cluster address here
        bootstrap_servers => "ip:9092"
        auto_offset_reset => "latest"
   }
}

filter {
#    Convert the request time in the Nginx log to Beijing time, and assign it to @ timestamp to ensure that the log time is consistent with @ timestamp
    date {
        match => ["requesttime", "dd/MMM/yyyy:HH:mm:ss Z +07:00"]
        target => "@timestamp"
}
#Introduce the third time parameter timestamp, add 8 hours to the above @ timestamp time, and assign it to timestamp to prevent ES from subtracting 8 hours from the time, resulting in 8 hours difference between the two times
    ruby {
        code => "event.set('timestamp', event.get('@timestamp').time.utc+7*60*60)"
    }
    mutate {
        convert => ["timestamp", "string"]
        gsub => ["timestamp", "T([\S\s]*?)Z", ""]
        gsub => ["timestamp", "-", "."]
    }
    mutate {
        remove_field => ["_index"]
        remove_field => ["_id"]
        remove_field => ["_type"]
        remove_field => ["_version"]
        remove_field => ["_score"]
        remove_field => ["host"]
        remove_field => ["log"]
        remove_field => ["referer"]
        remove_field => ["input"]
        remove_field => ["path"]
        remove_field => ["agent"]
    }
}
output {
    elasticsearch {
        hosts => ["https://ip:9200"]
	user => "elastic"
        password => "default"
        ssl_certificate_verification => false
	ilm_pattern => "{now/d}-000001"
        ilm_rollover_alias => "iis-alias"
        ilm_policy => "kafka-policy"
	}
}
